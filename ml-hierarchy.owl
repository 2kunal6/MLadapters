<?xml version="1.0"?>
<Ontology xmlns="http://www.w3.org/2002/07/owl#"
     xml:base="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:xml="http://www.w3.org/XML/1998/namespace"
     xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
     xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
     ontologyIRI="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy">
    <Prefix name="" IRI="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy"/>
    <Prefix name="owl" IRI="http://www.w3.org/2002/07/owl#"/>
    <Prefix name="rdf" IRI="http://www.w3.org/1999/02/22-rdf-syntax-ns#"/>
    <Prefix name="xml" IRI="http://www.w3.org/XML/1998/namespace"/>
    <Prefix name="xsd" IRI="http://www.w3.org/2001/XMLSchema#"/>
    <Prefix name="rdfs" IRI="http://www.w3.org/2000/01/rdf-schema#"/>
    <Declaration>
        <Class IRI="#Classification"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----C4.5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----C5.0"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----CART"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----CHAID"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----ConditionalDecisionTrees"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----DecisionStump"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----ID3"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----M5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Clustering"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Clustering----Kmeans"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Criterion"/>
    </Declaration>
    <Declaration>
        <Class IRI="#DecisionTreeParameter"/>
    </Declaration>
    <Declaration>
        <Class IRI="#MachineLearningAlgorithms"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Parameter"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----C4.5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----C5.0"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----CART"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----CHAID"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----ConditionalDecisionTrees"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----DecisionStump"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----ID3"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----M5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Splitter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#class_weight"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#fit"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#get_depth"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#get_n_leaves"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----cost_complexity_pruning_path----criterion"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----sample_weight"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----y"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit_predict"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit_transform"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----get_params"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----predict"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----score"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----set_params"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----transform"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----criterion"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#max_depth"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#min_samples_split"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#predict"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#splitter"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasCcpAlpha"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasDataParameter"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMaxDepth"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMaxFeatures"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMaxLeafNodes"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMinImpurityDecrease"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMinImpuritySplit"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMinSamplesLeaf"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMinSamplesSplit"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasMinWeightFractionLeaf"/>
    </Declaration>
    <Declaration>
        <DataProperty IRI="#hasRandomState"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#default_value"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#isSupervised"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#parameter_position"/>
    </Declaration>
    <SubClassOf>
        <Class IRI="#Classification"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree"/>
        <Class IRI="#Classification"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----C4.5"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----C5.0"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----CART"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----CHAID"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----ConditionalDecisionTrees"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----DecisionStump"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----ID3"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----M5"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Clustering"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Clustering----Kmeans"/>
        <Class IRI="#Clustering"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Criterion"/>
        <Class IRI="#DecisionTreeParameter"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#DecisionTreeParameter"/>
        <Class IRI="#Parameter"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree"/>
        <Class IRI="#Regression"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----C4.5"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----C5.0"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----CART"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----CHAID"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----ConditionalDecisionTrees"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----DecisionStump"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----ID3"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----M5"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Splitter"/>
        <Class IRI="#DecisionTreeParameter"/>
    </SubClassOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#class_weight"/>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#fit"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#get_depth"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#get_n_leaves"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
        <ObjectProperty IRI="#hasFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
        <ObjectProperty IRI="#hasParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction"/>
        <ObjectProperty abbreviatedIRI="owl:topObjectProperty"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----X"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----check_input"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----X"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----check_input"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----sample_weight"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----y"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----X"/>
        <ObjectProperty IRI="#predict"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----check_input"/>
        <ObjectProperty IRI="#predict"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction"/>
        <ObjectProperty IRI="#hasFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit_predict"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit_transform"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----get_params"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----predict"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----score"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----set_params"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----transform"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectProperty abbreviatedIRI="owl:topObjectProperty"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----criterion"/>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#max_depth"/>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#min_samples_split"/>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#predict"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#splitter"/>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
    </SubObjectPropertyOf>
    <ObjectPropertyDomain>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
        <ObjectAllValuesFrom>
            <ObjectProperty IRI="#hasDecisionTreeParameter"/>
            <Class IRI="#Classification----DecisionTree"/>
        </ObjectAllValuesFrom>
    </ObjectPropertyDomain>
    <ObjectPropertyDomain>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectAllValuesFrom>
            <ObjectProperty IRI="#hasParameter"/>
            <Class IRI="#MachineLearningAlgorithms"/>
        </ObjectAllValuesFrom>
    </ObjectPropertyDomain>
    <ObjectPropertyRange>
        <ObjectProperty IRI="#hasDecisionTreeParameter"/>
        <ObjectSomeValuesFrom>
            <ObjectProperty IRI="#hasParameter"/>
            <Class IRI="#DecisionTreeParameter"/>
        </ObjectSomeValuesFrom>
    </ObjectPropertyRange>
    <ObjectPropertyRange>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectSomeValuesFrom>
            <ObjectProperty IRI="#hasParameter"/>
            <Class IRI="#Parameter"/>
        </ObjectSomeValuesFrom>
    </ObjectPropertyRange>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasCcpAlpha"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasDataParameter"/>
        <DataProperty abbreviatedIRI="owl:topDataProperty"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
        <DataProperty IRI="#hasDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMaxDepth"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMaxFeatures"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMaxLeafNodes"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMinImpurityDecrease"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMinImpuritySplit"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMinSamplesLeaf"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMinSamplesSplit"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasMinWeightFractionLeaf"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <SubDataPropertyOf>
        <DataProperty IRI="#hasRandomState"/>
        <DataProperty IRI="#hasDecisionTreeDataParameter"/>
    </SubDataPropertyOf>
    <DataPropertyRange>
        <DataProperty IRI="#hasCcpAlpha"/>
        <Datatype abbreviatedIRI="xsd:float"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMaxDepth"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMaxFeatures"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMaxLeafNodes"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMinImpurityDecrease"/>
        <Datatype abbreviatedIRI="xsd:float"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMinImpuritySplit"/>
        <Datatype abbreviatedIRI="xsd:float"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMinSamplesLeaf"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMinSamplesSplit"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasMinWeightFractionLeaf"/>
        <Datatype abbreviatedIRI="xsd:float"/>
    </DataPropertyRange>
    <DataPropertyRange>
        <DataProperty IRI="#hasRandomState"/>
        <Datatype abbreviatedIRI="xsd:integer"/>
    </DataPropertyRange>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Classification----DecisionTree</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">true</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#Classification----DecisionTree</IRI>
        <Literal>DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset.

As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, of shape (n_samples, n_features) holding the training samples, and an array Y of integer values, shape (n_samples,), holding the class labels for the training samples.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Clustering</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">false</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Regression----DecisionTree</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">true</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#Regression----DecisionTree</IRI>
        <Literal>Decision trees can be applied to regression problems, using the DecisionTreeRegressor class.

As in the classification setting, the fit method will take as argument arrays X and y, only that in this case y is expected to have floating point values instead of integer values.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#class_weight</IRI>
        <Literal>dict = None</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#class_weight</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">1200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#fit</IRI>
        <Literal>Build a decision tree classifier from the training set (X, y).</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#get_depth</IRI>
        <Literal>Return the depth of the decision tree.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#get_n_leaves</IRI>
        <Literal>Return the number of leaves of the decision tree.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply</IRI>
        <Literal>Return the index of the leaf that each sample is predicted as.

Parameters: 
X{array-like, sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

check_inputbool, default=True
Allow to bypass several input checking. Don’t use this parameter unless you know what you do.


Returns:
X_leavesarray-like of shape (n_samples,)
For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">400</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----sample_weight</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">300</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----y</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----predict----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----predict----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----criterion</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#max_depth</IRI>
        <Literal>int = None</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#max_depth</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">300</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#min_samples_split</IRI>
        <Literal>float = 2</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#min_samples_split</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">400</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#predict</IRI>
        <Literal>Predict class or regression value for X.

Parameters:
X{array-like, sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.


Returns:
probandarray of shape (n_samples, n_classes) or list of n_outputs such arrays if n_outputs &gt; 1
The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#splitter</IRI>
        <Literal>str = ”best”</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#splitter</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
</Ontology>



<!-- Generated by the OWL API (version 4.5.9.2019-02-01T07:24:44Z) https://github.com/owlcs/owlapi -->

