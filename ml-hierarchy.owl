<?xml version="1.0"?>
<Ontology xmlns="http://www.w3.org/2002/07/owl#"
     xml:base="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:xml="http://www.w3.org/XML/1998/namespace"
     xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
     xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
     ontologyIRI="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy">
    <Prefix name="" IRI="http://www.semanticweb.org/kunal/ontologies/2020/10/ml-hierarchy"/>
    <Prefix name="owl" IRI="http://www.w3.org/2002/07/owl#"/>
    <Prefix name="rdf" IRI="http://www.w3.org/1999/02/22-rdf-syntax-ns#"/>
    <Prefix name="xml" IRI="http://www.w3.org/XML/1998/namespace"/>
    <Prefix name="xsd" IRI="http://www.w3.org/2001/XMLSchema#"/>
    <Prefix name="rdfs" IRI="http://www.w3.org/2000/01/rdf-schema#"/>
    <Declaration>
        <Class IRI="#Classification"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----C4.5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----C5.0"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----CART"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----CHAID"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----ConditionalDecisionTrees"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----DecisionStump"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----ID3"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Classification----DecisionTree----M5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Clustering"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Clustering----Kmeans"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Criterion"/>
    </Declaration>
    <Declaration>
        <Class IRI="#DecisionTreeParameter"/>
    </Declaration>
    <Declaration>
        <Class IRI="#MachineLearningAlgorithms"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Parameter"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----C4.5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----C5.0"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----CART"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----CHAID"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----ConditionalDecisionTrees"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----DecisionStump"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----ID3"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Regression----DecisionTree----M5"/>
    </Declaration>
    <Declaration>
        <Class IRI="#Splitter"/>
    </Declaration>
    <Declaration>
        <Class IRI="#classification----MLPClassifier"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#fit"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#get_depth"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#get_n_leaves"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----cost_complexity_pruning_path----criterion"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----sample_weight"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----y"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----X"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----check_input"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit_predict"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----fit_transform"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----get_params"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----predict"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----score"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----set_params"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasKmeansFunction----transform"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasMLPClassifierParameter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----ccp_alpha"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----class_weight"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----criterion"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_depth"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_features"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_leaf_nodes"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_impurity_decrease"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_impurity_split"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_samples_leaf"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_samples_split"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_weight_fraction_leaf"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----random_state"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----splitter"/>
    </Declaration>
    <Declaration>
        <ObjectProperty IRI="#predict"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#default_value"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#imports"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#isSupervised"/>
    </Declaration>
    <Declaration>
        <AnnotationProperty IRI="#parameter_position"/>
    </Declaration>
    <SubClassOf>
        <Class IRI="#Classification"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree"/>
        <Class IRI="#Classification"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----C4.5"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----C5.0"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----CART"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----CHAID"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----ConditionalDecisionTrees"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----DecisionStump"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----ID3"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Classification----DecisionTree----M5"/>
        <Class IRI="#Classification----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Clustering"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Clustering----Kmeans"/>
        <Class IRI="#Clustering"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Criterion"/>
        <Class IRI="#DecisionTreeParameter"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#DecisionTreeParameter"/>
        <Class IRI="#Parameter"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression"/>
        <Class IRI="#MachineLearningAlgorithms"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree"/>
        <Class IRI="#Regression"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----C4.5"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----C5.0"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----CART"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----CHAID"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----ConditionalDecisionTrees"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----DecisionStump"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----ID3"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Regression----DecisionTree----M5"/>
        <Class IRI="#Regression----DecisionTree"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#Splitter"/>
        <Class IRI="#DecisionTreeParameter"/>
    </SubClassOf>
    <SubClassOf>
        <Class IRI="#classification----MLPClassifier"/>
        <Class IRI="#Classification"/>
    </SubClassOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#fit"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#get_depth"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#get_n_leaves"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
        <ObjectProperty IRI="#hasFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction"/>
        <ObjectProperty abbreviatedIRI="owl:topObjectProperty"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----X"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply----check_input"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----apply"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----X"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----check_input"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----sample_weight"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----fit----y"/>
        <ObjectProperty IRI="#fit"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----X"/>
        <ObjectProperty IRI="#predict"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----predict----check_input"/>
        <ObjectProperty IRI="#predict"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction"/>
        <ObjectProperty IRI="#hasFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit_predict"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----fit_transform"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----get_params"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----predict"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----score"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----set_params"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasKmeansFunction----transform"/>
        <ObjectProperty IRI="#hasKmeansFunction"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasMLPClassifierParameter"/>
        <ObjectProperty IRI="#hasParameter"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectProperty abbreviatedIRI="owl:topObjectProperty"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----ccp_alpha"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----class_weight"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----criterion"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_depth"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_features"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----max_leaf_nodes"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_impurity_decrease"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_impurity_split"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_samples_leaf"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_samples_split"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----min_weight_fraction_leaf"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----random_state"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#hasParameter----hasDecisionTreeParameter----splitter"/>
        <ObjectProperty IRI="#hasFunction----hasDecisionTreeFunction----__init__"/>
    </SubObjectPropertyOf>
    <SubObjectPropertyOf>
        <ObjectProperty IRI="#predict"/>
        <ObjectProperty IRI="#hasDecisionTreeFunction"/>
    </SubObjectPropertyOf>
    <ObjectPropertyDomain>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectAllValuesFrom>
            <ObjectProperty IRI="#hasParameter"/>
            <Class IRI="#MachineLearningAlgorithms"/>
        </ObjectAllValuesFrom>
    </ObjectPropertyDomain>
    <ObjectPropertyRange>
        <ObjectProperty IRI="#hasParameter"/>
        <ObjectSomeValuesFrom>
            <ObjectProperty IRI="#hasParameter"/>
            <Class IRI="#Parameter"/>
        </ObjectSomeValuesFrom>
    </ObjectPropertyRange>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#imports"/>
        <IRI>#Classification----DecisionTree</IRI>
        <Literal>from sklearn.tree import DecisionTreeClassifier</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Classification----DecisionTree</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">true</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#Classification----DecisionTree</IRI>
        <Literal>DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset.

As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, of shape (n_samples, n_features) holding the training samples, and an array Y of integer values, shape (n_samples,), holding the class labels for the training samples.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Clustering</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">false</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#imports"/>
        <IRI>#Clustering----Kmeans</IRI>
        <Literal>from sklearn.cluster import KMeans</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#imports"/>
        <IRI>#Regression----DecisionTree</IRI>
        <Literal>from sklearn.tree import DecisionTreeRegressor</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#Regression----DecisionTree</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">true</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#Regression----DecisionTree</IRI>
        <Literal>Decision trees can be applied to regression problems, using the DecisionTreeRegressor class.

As in the classification setting, the fit method will take as argument arrays X and y, only that in this case y is expected to have floating point values instead of integer values.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#isSupervised"/>
        <IRI>#classification----MLPClassifier</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#boolean">true</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#classification----MLPClassifier</IRI>
        <Literal>MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.

It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.

This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#classification----MLPClassifier</IRI>
        <Literal>from sklearn.neural_network.MLPClassifier import MLPClassifier</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#fit</IRI>
        <Literal>Build a decision tree classifier from the training set (X, y).</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#get_depth</IRI>
        <Literal>Return the depth of the decision tree.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#get_n_leaves</IRI>
        <Literal>Return the number of leaves of the decision tree.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply</IRI>
        <Literal>Return the index of the leaf that each sample is predicted as.

Parameters: 
X{array-like, sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

check_inputbool, default=True
Allow to bypass several input checking. Don’t use this parameter unless you know what you do.


Returns:
X_leavesarray-like of shape (n_samples,)
For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----apply----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">400</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----sample_weight</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">300</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----fit----y</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----predict----X</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasFunction----hasDecisionTreeFunction----predict----check_input</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----ccp_alpha</IRI>
        <Literal>0.0</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----ccp_alpha</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#integer">1300</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----class_weight</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#integer">1200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----criterion</IRI>
        <Literal>gini</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----criterion</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----max_depth</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">300</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----max_features</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">700</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----max_leaf_nodes</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">900</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_impurity_decrease</IRI>
        <Literal>0.0</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_impurity_decrease</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">1000</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_impurity_split</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#integer">1100</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_samples_leaf</IRI>
        <Literal>1</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_samples_leaf</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">500</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_samples_split</IRI>
        <Literal>2</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_samples_split</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">400</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_weight_fraction_leaf</IRI>
        <Literal>0.0</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----min_weight_fraction_leaf</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">600</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----random_state</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">800</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#default_value"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----splitter</IRI>
        <Literal>best</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty IRI="#parameter_position"/>
        <IRI>#hasParameter----hasDecisionTreeParameter----splitter</IRI>
        <Literal datatypeIRI="http://www.w3.org/2001/XMLSchema#int">200</Literal>
    </AnnotationAssertion>
    <AnnotationAssertion>
        <AnnotationProperty abbreviatedIRI="rdfs:comment"/>
        <IRI>#predict</IRI>
        <Literal>Predict class or regression value for X.

Parameters:
X{array-like, sparse matrix} of shape (n_samples, n_features)
The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.


Returns:
probandarray of shape (n_samples, n_classes) or list of n_outputs such arrays if n_outputs &gt; 1
The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.</Literal>
    </AnnotationAssertion>
</Ontology>



<!-- Generated by the OWL API (version 4.5.9.2019-02-01T07:24:44Z) https://github.com/owlcs/owlapi -->

