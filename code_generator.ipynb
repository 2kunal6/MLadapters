{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'owlready2' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-52344b89a7a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mowlready2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowlready2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'owlready2' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import file_util\n",
    "from util.graph_util import Graph\n",
    "from service import python_content_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_propagation = {}\n",
    "cp_map = {}\n",
    "\n",
    "template = \"\"\"\n",
    "{import_statements}\\n\\n\n",
    "class {class_name}({parent}):\n",
    "    {functions}\n",
    "\"\"\"\n",
    "\n",
    "def generate_imports_from_template(node):\n",
    "    import_template = \"\"\"\\n{lib}\\n{core}\"\"\"\n",
    "    core = node.core_import\n",
    "    lib = node.lib_import\n",
    "    return import_template.format(\n",
    "        lib=node.lib_import.first() if lib else \"\",\n",
    "        core=node.core_import.first() if core else \"\")\n",
    "    \n",
    "def generate_class_from_template(node, parent, functions):\n",
    "    return template.format(\n",
    "        import_statements=generate_imports_from_template(node), \n",
    "        class_name=node.label.first(), \n",
    "        parent= parent.label.first() if parent else \"\", \n",
    "        functions=functions)\n",
    "\n",
    "def function_name_handler(func_name):\n",
    "    if func_name == \"init\":\n",
    "        return \"__init__\"\n",
    "    return func_name\n",
    "        \n",
    "def generate_model_init_from_template(node, params, variables):\n",
    "    if node.core_import:\n",
    "        lib_name = node.core_import.first().split()[-1]\n",
    "        variables.extend(params.split(\", \"))\n",
    "        variables = set(variables)\n",
    "        stmts = [\"{var} = self.{var}\".format(var=var) for var in variables]\n",
    "        func_params = \",\\n\\t\\t\\t\".join(stmts)\n",
    "        return \"\\n\\t\\tself.model = {lib_name}({func_params})\".format(\n",
    "            lib_name=lib_name, func_params=func_params)\n",
    "    return \"\"\n",
    "\n",
    "def generate_function_body_from_template(node, func, target):\n",
    "    print(\"FUNC: \", func.label.first())\n",
    "    func_name = func.label.first()\n",
    "    if func_name == \"init\":\n",
    "        variables = [obj.label.first() for obj in target]\n",
    "        stmts = [\"self.{var} = {var}\".format(var=var) for var in variables]\n",
    "        stmt = \"\\n\\t\\t\".join(stmts)\n",
    "        params = get_inherited_params(node)\n",
    "        if params:\n",
    "            stmt = stmt + \"\\n\\t\\t{parent}.__init__(self, {params})\".format(\n",
    "                parent=cp_map[node].label.first(), params=params)\n",
    "        stmt = stmt + generate_model_init_from_template(node, params, variables)\n",
    "        return stmt\n",
    "    else:\n",
    "        variables = [obj.label.first() for obj in target]\n",
    "        stmts = [\"{var}={var}\".format(var=var) for var in variables]\n",
    "        params = \",\\n\\t\\t\\t\".join(stmts)\n",
    "        return \"return self.model.{func_name}({params})\".format(\n",
    "            func_name=func_name,\n",
    "            params=params\n",
    "        )\n",
    "        \n",
    "\n",
    "def generate_function_param_from_template(node, target):\n",
    "    params = \"\"\n",
    "    param_template = \"{var} = {value}\"\n",
    "    for obj in target:\n",
    "        if not obj.default:\n",
    "            param = obj.label.first()\n",
    "        else:\n",
    "            param = param_template.format(\n",
    "                var=obj.label.first(), value=obj.default.first())\n",
    "        params = params + \", \" + param\n",
    "    inherited_params = get_inherited_params(node)\n",
    "    if inherited_params:\n",
    "        params = \", \" + inherited_params + params \n",
    "    return params\n",
    "\n",
    "def generate_function_from_template(node, func):\n",
    "    func_template = \"\"\"\n",
    "    def {func_name}(self{params}):\n",
    "        {statements}\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n---------------------\")\n",
    "    print(\"LABEL: \",func.label[0])\n",
    "    var = func.label.first()\n",
    "    target = eval(\"node.\"+var)\n",
    "    print(\"TARGET: \",target)\n",
    "    if var == \"init\":\n",
    "        for child in node.descendants():\n",
    "            if child != node:\n",
    "                if member_propagation.get(child):\n",
    "                    member_propagation[child] = member_propagation[child] + target\n",
    "                else:\n",
    "                    member_propagation[child] = target\n",
    "    if target:\n",
    "        func = func_template.format(\n",
    "            func_name=function_name_handler(func.label.first()),\n",
    "            params=generate_function_param_from_template(node, target),\n",
    "            statements=generate_function_body_from_template(node, func, target)\n",
    "        )\n",
    "        return func\n",
    "\n",
    "def get_inherited_params(node):\n",
    "    inherited_variables = member_propagation.get(node)\n",
    "    print(\"INH_P: \", inherited_variables)\n",
    "    if inherited_variables:\n",
    "        var = [obj.label.first() for obj in inherited_variables]\n",
    "        params = \", \".join(var)\n",
    "        return params\n",
    "    return \"\"\n",
    "    \n",
    "def generate_init_by_member_propagation(node):\n",
    "    func_template = \"\"\"\n",
    "    def __init__(self, {params}):\n",
    "        {parent}.__init__(self, {params}){stmt}\n",
    "    \"\"\"\n",
    "    params = get_inherited_params(node)\n",
    "    return func_template.format(\n",
    "        params=params,\n",
    "        parent=cp_map[node].label.first(),\n",
    "        stmt=generate_model_init_from_template(node, params, [])\n",
    "    )\n",
    "    \n",
    "    \n",
    "def generate_functions_from_template(node):\n",
    "    function_names = set()\n",
    "    func_data = \"\"\n",
    "    for func in node.get_class_properties():\n",
    "        if func.label:\n",
    "            func_data = func_data + generate_function_from_template(node, func)\n",
    "            function_names.add(func.label[0])\n",
    "    if not func_data and member_propagation.get(node):\n",
    "            func_data = generate_init_by_member_propagation(node)\n",
    "    return func_data\n",
    "        \n",
    "\n",
    "def create_file_contents(node, child_parent_map):\n",
    "    print(node.label)\n",
    "    global cp_map\n",
    "    cp_map = child_parent_map\n",
    "    parent = cp_map[node]\n",
    "    if parent:\n",
    "        print(\"PARENT: \", parent)\n",
    "    func_data = generate_functions_from_template(node)\n",
    "    if not func_data:\n",
    "        func_data = \"pass\"\n",
    "    content = generate_class_from_template(node, parent, func_data)\n",
    "    print(content)\n",
    "    return content\n",
    "    #print(\"MEM_PROP: \", member_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ml_algorithms.core_import, ml_algorithms.default, ml_algorithms.import, ml_algorithms.lib_import, ml_algorithms.mla:default, ml_algorithms.mla:dtype]\n",
      "[ml_algorithms.Bayesian, ml_algorithms.MLalgoritthms, ml_algorithms.Classification, ml_algorithms.Clustering, ml_algorithms.GRU, ml_algorithms.RNNBase, ml_algorithms.LSTM, ml_algorithms.LassoRegression, ml_algorithms.Regression, ml_algorithms.max_iter, ml_algorithms.LassoTempReg, ml_algorithms.alpha, ml_algorithms.LinearRegression, ml_algorithms.NeuralNetwork, ml_algorithms.RNN, ml_algorithms.nonlinearity, ml_algorithms.batch_first, ml_algorithms.bias, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.hidden_size, ml_algorithms.input_size, ml_algorithms.num_layers, ml_algorithms.X, ml_algorithms.sample_weight, ml_algorithms.y, ml_algorithms.copy_X, ml_algorithms.fit_intercept, ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.RidgeRegression, ml_algorithms.parameters, ml_algorithms.attributes, ml_algorithms.coef_, ml_algorithms.deep, ml_algorithms.intercept_, ml_algorithms.n_iter_, ml_algorithms.params, ml_algorithms.positive, ml_algorithms.random_state, ml_algorithms.rank_, ml_algorithms.selection, ml_algorithms.singular_, ml_algorithms.solver, ml_algorithms.tol, ml_algorithms.warm_start]\n",
      "ml_algorithms.Bayesian\n",
      "['Bayesian']\n",
      "ml_algorithms.MLalgoritthms\n",
      "['MLalgorithms']\n",
      "ml_algorithms.Classification\n",
      "['Classification']\n",
      "ml_algorithms.Clustering\n",
      "['Clustering']\n",
      "ml_algorithms.GRU\n",
      "['GRU']\n",
      "ml_algorithms.RNNBase\n",
      "['RNNBase']\n",
      "ml_algorithms.LSTM\n",
      "['LSTM']\n",
      "ml_algorithms.LassoRegression\n",
      "['LassoRegression']\n",
      "ml_algorithms.Regression\n",
      "['Regression']\n",
      "ml_algorithms.max_iter\n",
      "['max_iter']\n",
      "ml_algorithms.LassoTempReg\n",
      "['LassoTempReg']\n",
      "ml_algorithms.alpha\n",
      "['alpha']\n",
      "ml_algorithms.LinearRegression\n",
      "['LinearRegression']\n",
      "ml_algorithms.NeuralNetwork\n",
      "['NeuralNetwork']\n",
      "ml_algorithms.RNN\n",
      "['RNN']\n",
      "ml_algorithms.nonlinearity\n",
      "['nonlinearity']\n",
      "ml_algorithms.batch_first\n",
      "['batch_first']\n",
      "ml_algorithms.bias\n",
      "['bias']\n",
      "ml_algorithms.bidirectional\n",
      "['bidirectional']\n",
      "ml_algorithms.dropout\n",
      "['dropout']\n",
      "ml_algorithms.hidden_size\n",
      "['hidden_size']\n",
      "ml_algorithms.input_size\n",
      "['input_size']\n",
      "ml_algorithms.num_layers\n",
      "['num_layers']\n",
      "ml_algorithms.X\n",
      "['X']\n",
      "ml_algorithms.sample_weight\n",
      "['sample_weight']\n",
      "ml_algorithms.y\n",
      "['y']\n",
      "ml_algorithms.copy_X\n",
      "['copy_X']\n",
      "ml_algorithms.fit_intercept\n",
      "['fit_intercept']\n",
      "ml_algorithms.n_jobs\n",
      "['n_jobs']\n",
      "ml_algorithms.normalize\n",
      "['normalize']\n",
      "ml_algorithms.RidgeRegression\n",
      "['RidgeRegression']\n",
      "ml_algorithms.parameters\n",
      "['parameters']\n",
      "ml_algorithms.attributes\n",
      "['attributes']\n",
      "ml_algorithms.coef_\n",
      "['coef_']\n",
      "ml_algorithms.deep\n",
      "['deep']\n",
      "ml_algorithms.intercept_\n",
      "['intercept_']\n",
      "ml_algorithms.n_iter_\n",
      "['n_iter_']\n",
      "ml_algorithms.params\n",
      "['params']\n",
      "ml_algorithms.positive\n",
      "['positive']\n",
      "ml_algorithms.random_state\n",
      "['random_state']\n",
      "ml_algorithms.rank_\n",
      "['rank_']\n",
      "ml_algorithms.selection\n",
      "['selection']\n",
      "ml_algorithms.singular_\n",
      "['singular_']\n",
      "ml_algorithms.solver\n",
      "['solver']\n",
      "ml_algorithms.tol\n",
      "['tol']\n",
      "ml_algorithms.warm_start\n",
      "['warm_start']\n",
      "['MLalgorithms']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class MLalgorithms():\n",
      "    pass\n",
      "\n",
      "['Bayesian']\n",
      "PARENT:  ml_algorithms.MLalgoritthms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class Bayesian(MLalgorithms):\n",
      "    pass\n",
      "\n",
      "['Classification']\n",
      "PARENT:  ml_algorithms.MLalgoritthms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class Classification(MLalgorithms):\n",
      "    pass\n",
      "\n",
      "['Clustering']\n",
      "PARENT:  ml_algorithms.MLalgoritthms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class Clustering(MLalgorithms):\n",
      "    pass\n",
      "\n",
      "['Regression']\n",
      "PARENT:  ml_algorithms.MLalgoritthms\n",
      "\n",
      "---------------------\n",
      "LABEL:  init\n",
      "TARGET:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept]\n",
      "INH_P:  None\n",
      "FUNC:  init\n",
      "INH_P:  None\n",
      "\n",
      "---------------------\n",
      "LABEL:  fit\n",
      "TARGET:  [ml_algorithms.y, ml_algorithms.X, ml_algorithms.sample_weight]\n",
      "INH_P:  None\n",
      "FUNC:  fit\n",
      "\n",
      "---------------------\n",
      "LABEL:  predict\n",
      "TARGET:  [ml_algorithms.X]\n",
      "INH_P:  None\n",
      "FUNC:  predict\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class Regression(MLalgorithms):\n",
      "    \n",
      "    def __init__(self, n_jobs = None, normalize, copy_X, fit_intercept):\n",
      "        self.n_jobs = n_jobs\n",
      "\t\tself.normalize = normalize\n",
      "\t\tself.copy_X = copy_X\n",
      "\t\tself.fit_intercept = fit_intercept\n",
      "    \n",
      "    \n",
      "    def fit(self, y, X, sample_weight):\n",
      "        return self.model.fit(y=y,\n",
      "\t\t\tX=X,\n",
      "\t\t\tsample_weight=sample_weight)\n",
      "    \n",
      "    \n",
      "    def predict(self, X):\n",
      "        return self.model.predict(X=X)\n",
      "    \n",
      "    \n",
      "\n",
      "['NeuralNetwork']\n",
      "PARENT:  ml_algorithms.MLalgoritthms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class NeuralNetwork(MLalgorithms):\n",
      "    pass\n",
      "\n",
      "['LassoRegression']\n",
      "PARENT:  ml_algorithms.Regression\n",
      "\n",
      "---------------------\n",
      "LABEL:  init\n",
      "TARGET:  [ml_algorithms.max_iter]\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept]\n",
      "FUNC:  init\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept]\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import Lasso\n",
      "\n",
      "\n",
      "class LassoRegression(Regression):\n",
      "    \n",
      "    def __init__(self, n_jobs, normalize, copy_X, fit_intercept, max_iter):\n",
      "        self.max_iter = max_iter\n",
      "\t\tRegression.__init__(self, n_jobs, normalize, copy_X, fit_intercept)\n",
      "\t\tself.model = Lasso(max_iter = self.max_iter,\n",
      "\t\t\tnormalize = self.normalize,\n",
      "\t\t\tn_jobs = self.n_jobs,\n",
      "\t\t\tcopy_X = self.copy_X,\n",
      "\t\t\tfit_intercept = self.fit_intercept)\n",
      "    \n",
      "    \n",
      "\n",
      "['LinearRegression']\n",
      "PARENT:  ml_algorithms.Regression\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept]\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "\n",
      "class LinearRegression(Regression):\n",
      "    \n",
      "    def __init__(self, n_jobs, normalize, copy_X, fit_intercept):\n",
      "        Regression.__init__(self, n_jobs, normalize, copy_X, fit_intercept)\n",
      "\t\tself.model = LinearRegression(copy_X = self.copy_X,\n",
      "\t\t\tn_jobs = self.n_jobs,\n",
      "\t\t\tfit_intercept = self.fit_intercept,\n",
      "\t\t\tnormalize = self.normalize)\n",
      "    \n",
      "\n",
      "['RidgeRegression']\n",
      "PARENT:  ml_algorithms.Regression\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept]\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.linear_model import RidgeRegression\n",
      "\n",
      "\n",
      "class RidgeRegression(Regression):\n",
      "    \n",
      "    def __init__(self, n_jobs, normalize, copy_X, fit_intercept):\n",
      "        Regression.__init__(self, n_jobs, normalize, copy_X, fit_intercept)\n",
      "\t\tself.model = RidgeRegression(copy_X = self.copy_X,\n",
      "\t\t\tn_jobs = self.n_jobs,\n",
      "\t\t\tfit_intercept = self.fit_intercept,\n",
      "\t\t\tnormalize = self.normalize)\n",
      "    \n",
      "\n",
      "['RNNBase']\n",
      "PARENT:  ml_algorithms.NeuralNetwork\n",
      "\n",
      "---------------------\n",
      "LABEL:  init\n",
      "TARGET:  [ml_algorithms.input_size, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.num_layers, ml_algorithms.bias, ml_algorithms.hidden_size, ml_algorithms.batch_first]\n",
      "INH_P:  None\n",
      "FUNC:  init\n",
      "INH_P:  None\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class RNNBase(NeuralNetwork):\n",
      "    \n",
      "    def __init__(self, input_size, bidirectional = False, dropout = 0, num_layers = 1, bias = True, hidden_size, batch_first = False):\n",
      "        self.input_size = input_size\n",
      "\t\tself.bidirectional = bidirectional\n",
      "\t\tself.dropout = dropout\n",
      "\t\tself.num_layers = num_layers\n",
      "\t\tself.bias = bias\n",
      "\t\tself.hidden_size = hidden_size\n",
      "\t\tself.batch_first = batch_first\n",
      "    \n",
      "    \n",
      "\n",
      "['LassoTempReg']\n",
      "PARENT:  ml_algorithms.LassoRegression\n",
      "\n",
      "---------------------\n",
      "LABEL:  init\n",
      "TARGET:  [ml_algorithms.alpha]\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept, ml_algorithms.max_iter]\n",
      "FUNC:  init\n",
      "INH_P:  [ml_algorithms.n_jobs, ml_algorithms.normalize, ml_algorithms.copy_X, ml_algorithms.fit_intercept, ml_algorithms.max_iter]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class LassoTempReg(LassoRegression):\n",
      "    \n",
      "    def __init__(self, n_jobs, normalize, copy_X, fit_intercept, max_iter, alpha):\n",
      "        self.alpha = alpha\n",
      "\t\tLassoRegression.__init__(self, n_jobs, normalize, copy_X, fit_intercept, max_iter)\n",
      "    \n",
      "    \n",
      "\n",
      "['GRU']\n",
      "PARENT:  ml_algorithms.RNNBase\n",
      "INH_P:  [ml_algorithms.input_size, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.num_layers, ml_algorithms.bias, ml_algorithms.hidden_size, ml_algorithms.batch_first]\n",
      "\n",
      "\n",
      "\n",
      "import torch.nn.GRU as GRU\n",
      "\n",
      "\n",
      "class GRU(RNNBase):\n",
      "    \n",
      "    def __init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first):\n",
      "        RNNBase.__init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first)\n",
      "\t\tself.model = GRU(hidden_size = self.hidden_size,\n",
      "\t\t\tbatch_first = self.batch_first,\n",
      "\t\t\tdropout = self.dropout,\n",
      "\t\t\tinput_size = self.input_size,\n",
      "\t\t\tbias = self.bias,\n",
      "\t\t\tbidirectional = self.bidirectional,\n",
      "\t\t\tnum_layers = self.num_layers)\n",
      "    \n",
      "\n",
      "['LSTM']\n",
      "PARENT:  ml_algorithms.RNNBase\n",
      "INH_P:  [ml_algorithms.input_size, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.num_layers, ml_algorithms.bias, ml_algorithms.hidden_size, ml_algorithms.batch_first]\n",
      "\n",
      "\n",
      "\n",
      "import torch.nn.LSTM as LSTM\n",
      "\n",
      "\n",
      "class LSTM(RNNBase):\n",
      "    \n",
      "    def __init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first):\n",
      "        RNNBase.__init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first)\n",
      "\t\tself.model = LSTM(hidden_size = self.hidden_size,\n",
      "\t\t\tbatch_first = self.batch_first,\n",
      "\t\t\tdropout = self.dropout,\n",
      "\t\t\tinput_size = self.input_size,\n",
      "\t\t\tbias = self.bias,\n",
      "\t\t\tbidirectional = self.bidirectional,\n",
      "\t\t\tnum_layers = self.num_layers)\n",
      "    \n",
      "\n",
      "['RNN']\n",
      "PARENT:  ml_algorithms.RNNBase\n",
      "\n",
      "---------------------\n",
      "LABEL:  init\n",
      "TARGET:  [ml_algorithms.nonlinearity]\n",
      "INH_P:  [ml_algorithms.input_size, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.num_layers, ml_algorithms.bias, ml_algorithms.hidden_size, ml_algorithms.batch_first]\n",
      "FUNC:  init\n",
      "INH_P:  [ml_algorithms.input_size, ml_algorithms.bidirectional, ml_algorithms.dropout, ml_algorithms.num_layers, ml_algorithms.bias, ml_algorithms.hidden_size, ml_algorithms.batch_first]\n",
      "\n",
      "\n",
      "\n",
      "import torch.nn.RNN as RNN\n",
      "\n",
      "\n",
      "class RNN(RNNBase):\n",
      "    \n",
      "    def __init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first, nonlinearity = 'tanh'):\n",
      "        self.nonlinearity = nonlinearity\n",
      "\t\tRNNBase.__init__(self, input_size, bidirectional, dropout, num_layers, bias, hidden_size, batch_first)\n",
      "\t\tself.model = RNN(hidden_size = self.hidden_size,\n",
      "\t\t\tbatch_first = self.batch_first,\n",
      "\t\t\tdropout = self.dropout,\n",
      "\t\t\tinput_size = self.input_size,\n",
      "\t\t\tnonlinearity = self.nonlinearity,\n",
      "\t\t\tbias = self.bias,\n",
      "\t\t\tbidirectional = self.bidirectional,\n",
      "\t\t\tnum_layers = self.num_layers)\n",
      "    \n",
      "    \n",
      "\n",
      "['MLalgorithms', 'MLalgorithms\\\\Bayesian', 'MLalgorithms\\\\Classification', 'MLalgorithms\\\\Clustering', 'MLalgorithms\\\\Regression', 'MLalgorithms\\\\NeuralNetwork', 'MLalgorithms\\\\Regression\\\\LassoRegression', 'MLalgorithms\\\\Regression\\\\LinearRegression', 'MLalgorithms\\\\Regression\\\\RidgeRegression', 'MLalgorithms\\\\NeuralNetwork\\\\RNNBase', 'MLalgorithms\\\\Regression\\\\LassoRegression\\\\LassoTempReg', 'MLalgorithms\\\\NeuralNetwork\\\\RNNBase\\\\GRU', 'MLalgorithms\\\\NeuralNetwork\\\\RNNBase\\\\LSTM', 'MLalgorithms\\\\NeuralNetwork\\\\RNNBase\\\\RNN']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "child_parent_map = {}\n",
    "onto = get_ontology(\"ml_algorithms.owl\").load()\n",
    "queue = []\n",
    "root_class = None\n",
    "print([i for i in onto.annotation_properties()])\n",
    "print(list(onto.classes()))\n",
    "for onto_class in list(onto.classes()):\n",
    "    print(onto_class)\n",
    "    print(onto_class.label)\n",
    "    if(onto_class.label[0] == 'MLalgorithms'):\n",
    "        root_class = onto_class\n",
    "\n",
    "queue.append(root_class)\n",
    "dir_structure = [root_class.label[0]]\n",
    "file_path = []\n",
    "child_parent_map[root_class] = None\n",
    "while queue:\n",
    "    node = queue.pop(0)\n",
    "    file = dir_structure.pop(0)\n",
    "    if onto.get_children_of(node):\n",
    "        file_util.create_folders_and_subfolders(file)\n",
    "    content = create_file_contents(node, child_parent_map)\n",
    "    file_util.create_and_write_file(file + \".py\", content)\n",
    "    file_path.append(file)\n",
    "    for child in onto.get_children_of(node):\n",
    "        queue.append(child)\n",
    "        child_parent_map[child] = node\n",
    "        dir_structure.append(os.path.join(file, child.label[0]))\n",
    "\n",
    "del member_propagation\n",
    "del cp_map\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(root_class.descendants()):\n",
    "    if i.label[0] == 'Regression':\n",
    "        for j in list(i.descendants()):\n",
    "            print(j.label[0])\n",
    "            for k in list(onto.object_properties()):\n",
    "                try:\n",
    "                    print(\"df\",k)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._model.printf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student:\n",
    "    def printf(self, X):\n",
    "        print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(ML):\n",
    "    def __init__(self, d, e):\n",
    "        self.x = d\n",
    "        self.y = e\n",
    "        ML.__init__(self, d,e)\n",
    "        self._model = student()\n",
    "    \n",
    "    def printl(self):\n",
    "        print(self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tree = DT(5,4)\n",
    "tree.fit(5,4)\n",
    "tree.printl()\n",
    "tree._model.printf(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        print(\"A\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self, name):\n",
    "        print(\"B\")\n",
    "        A.__init__(self, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(B):\n",
    "    def __init_(self, a, b):\n",
    "        self.b = b\n",
    "        print(\"C\")\n",
    "        B.__init__(self, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "c = B(\"varun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'varun'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"A\"] = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"A\"].extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"A\"] = d[\"A\"].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"A\"].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  True\n",
    "b = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-fc7ffa363c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"HI\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in None:\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"from sklearn.linear_model import Lasso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lasso'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {'obj1': [1,2,3], 'obj2': [1,2,3], 'obj3': [1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "child='obj1'\n",
    "temp[child].extend([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[6,7] + [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj1': [6, 7], 'obj2': [1, 2, 3], 'obj3': [1, 2, 3]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
